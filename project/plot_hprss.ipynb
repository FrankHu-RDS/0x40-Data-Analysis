{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Harmonic-percussive source separation\n",
    "\n",
    "This notebook illustrates how to separate an audio signal into\n",
    "its harmonic and percussive components.\n",
    "\n",
    "We'll compare the original median-filtering based approach of\n",
    "`Fitzgerald, 2010 <http://arrow.dit.ie/cgi/viewcontent.cgi?article=1078&context=argcon>`_\n",
    "and its margin-based extension due to `Dreidger, Mueller and Disch, 2014\n",
    "<http://www.terasoft.com.tw/conf/ismir2014/proceedings/T110_127_Paper.pdf>`_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ran into this issue\n",
    "# https://github.com/librosa/librosa/issues/219\n",
    "# if using mac/linux I had to install ffmpeg to parse the audio. If using windows you might need to do something else. Librosa uses a 3rd party app to load audio files, and it doesn't tell you how to fix errors if there are any with loading \n",
    "# the audio files. \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import time\n",
    "import math\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xml.dom.minidom\n",
    "import os\n",
    "from os.path import exists\n",
    "from collections import defaultdict\n",
    "\n",
    "## Below is the example code on how to utilize Librosa with harmonic-percussive source seperation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an example clip with harmonics and percussives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load('chocomint.flac', duration=5, offset=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the short-time Fourier transform of y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "D = librosa.stft(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose D into harmonic and percussive components\n",
    "\n",
    "$D = D_\\text{harmonic} + D_\\text{percussive}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "D_harmonic, D_percussive = librosa.decompose.hpss(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the two components along with the original spectrogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Pre-compute a global reference power from the input spectrum\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default HPSS above assigns energy to each time-frequency bin according to\n",
    "whether a horizontal (harmonic) or vertical (percussive) filter responds higher\n",
    "at that position.\n",
    "\n",
    "This assumes that all energy belongs to either a harmonic or percussive source,\n",
    "but does not handle \"noise\" well.  Noise energy ends up getting spread between\n",
    "D_harmonic and D_percussive.\n",
    "\n",
    "If we instead require that the horizontal filter responds more than the vertical\n",
    "filter *by at least some margin*, and vice versa, then noise can be removed\n",
    "from both components.\n",
    "\n",
    "Note: the default (above) corresponds to margin=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's compute separations for a few different margins and compare the results below\n",
    "D_harmonic2, D_percussive2 = librosa.decompose.hpss(D, margin=2)\n",
    "D_harmonic4, D_percussive4 = librosa.decompose.hpss(D, margin=4)\n",
    "D_harmonic8, D_percussive8 = librosa.decompose.hpss(D, margin=8)\n",
    "D_harmonic16, D_percussive16 = librosa.decompose.hpss(D, margin=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plots below, note that vibrato has been suppressed from the harmonic\n",
    "components, and vocals have been suppressed in the percussive components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=2, sharex=True, sharey=True, figsize=(10, 10))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0, 0])\n",
    "ax[0, 0].set(title='Harmonic')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0, 1])\n",
    "ax[0, 1].set(title='Percussive')\n",
    "print(D_percussive)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[4, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[4, 1])\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i, 0].set(ylabel='margin={:d}'.format(2**i))\n",
    "    ax[i, 0].label_outer()\n",
    "    ax[i, 1].label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is where code starts for 0x40 hues to parse respacks and audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse for the song names and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respack_folders = []\n",
    "for directory, sub_directories, files in os.walk('./Respacks/'):\n",
    "    for folder in sub_directories:\n",
    "        if folder != 'Songs' and folder != 'characters' and folder != 'Images':\n",
    "            respack_folders.append(folder)\n",
    "print(respack_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and get the rhythm and build up rhythm text from XML files and put them into hashmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhythm_map = defaultdict(str)\n",
    "build_up_rhythm_map = defaultdict(str)\n",
    "\n",
    "for folder in respack_folders:\n",
    "    path_name = './Respacks/' + folder + '/songs.xml'\n",
    "    print(path_name)\n",
    "    if exists(path_name):\n",
    "        song_xml = xml.dom.minidom.parse(path_name)\n",
    "        songs = song_xml.getElementsByTagName('song')\n",
    "        for song in songs:\n",
    "            # parsing rhythms\n",
    "            curr_song_name = song.getAttribute('name')\n",
    "            if len(song.getElementsByTagName('rhythm')) > 0:\n",
    "                rhythm_map[curr_song_name] = song.getElementsByTagName('rhythm')[0].firstChild.nodeValue\n",
    "            if len(song.getElementsByTagName('buildup')) > 0:\n",
    "                build_up_name = song.getElementsByTagName('buildup')[0].firstChild.nodeValue\n",
    "                if len(song.getElementsByTagName('buildupRhythm')) > 0:\n",
    "                    build_up_rhythm_map[build_up_name] = song.getElementsByTagName('buildupRhythm')[0].firstChild.nodeValue\n",
    "            \n",
    "    else:\n",
    "        print('bad path name ' + str(path_name))\n",
    "\n",
    "print(rhythm_map.items())\n",
    "print(build_up_rhythm_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def parseSong(y, sr):\n",
    "    T = 30.0    # seconds\n",
    "    t = np.linspace(0, T, int(T*sr), endpoint=False) # time variable\n",
    "    x = 0.5*np.sin(2*np.pi*220*t)# pure sine wave at 220 Hz\n",
    "    D = librosa.stft(y)\n",
    "    ret_dict = dict()\n",
    "    ret_dict['D_harmonic4'], ret_dict['D_percussive4'] = librosa.decompose.hpss(D, margin=4)\n",
    "    ret_dict['D_harmonic16'], ret_dict['D_percussive16'] = librosa.decompose.hpss(D, margin=16)\n",
    "    # ret_dict['spectral_centroids'] = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "    # ret_dict['spectral_rolloff'] = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\n",
    "    \n",
    "    \n",
    "    #spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]\n",
    "    #spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]\n",
    "    #spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]\n",
    "    #ret_dict['spectral_bandwidth_2'] = spectral_bandwidth_2\n",
    "    #ret_dict['spectral_bandwidth_3'] = spectral_bandwidth_3\n",
    "    #ret_dict['spectral_bandwidth_4'] = spectral_bandwidth_4\n",
    "    return ret_dict\n",
    "\n",
    "# dict(audio_name -> dict(features -> values))\n",
    "audio_rhythm_feature_map = defaultdict(dict)\n",
    "audio_build_up_rhythm_feature_map = defaultdict(dict)\n",
    "\n",
    "for folder in respack_folders:\n",
    "    path_name = './Respacks/' + folder + '/songs.xml'\n",
    "    print(path_name)\n",
    "    if exists(path_name):\n",
    "        song_xml = xml.dom.minidom.parse(path_name)\n",
    "        songs = song_xml.getElementsByTagName('song')\n",
    "        for song in songs:\n",
    "            # parsing rhythms\n",
    "            curr_song_name = song.getAttribute('name')\n",
    "            song_path_name = None\n",
    "            is_rhythm = False\n",
    "            is_build_up = False\n",
    "            if len(song.getElementsByTagName('rhythm')) > 0:\n",
    "                is_rhythm = True\n",
    "                song_path_name = path_name = './Respacks/' + folder +'/Songs/' + curr_song_name + '.mp3'\n",
    "            \n",
    "            if len(song.getElementsByTagName('buildup')) > 0:\n",
    "                is_build_up - True\n",
    "                build_up_name = song.getElementsByTagName('buildup')[0].firstChild.nodeValue\n",
    "                song_path_name = path_name = './Respacks/' + folder +'/Songs/' + build_up_name + '.mp3'\n",
    "                    \n",
    "            # load the song\n",
    "            if exists(song_path_name):\n",
    "                print('parsing ' + str(song_path_name))\n",
    "                try:\n",
    "                    y, sr = librosa.load(song_path_name, duration=5, offset=10)\n",
    "                    if is_rhythm:\n",
    "                        audio_rhythm_feature_map[curr_song_name] = parseSong(y,sr)\n",
    "                    elif is_build_up:\n",
    "                        audio_build_up_rhythm_feature_map[build_up_name] = parseSong(y,sr)\n",
    "                except Exception as e:\n",
    "                    print('exception occurred')\n",
    "                    print(e)\n",
    "            else:\n",
    "                print('file name doesn\\'t exist ' + rhythm_song_path_name)\n",
    "    else:\n",
    "        print('bad path name ' + str(path_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to print out the parsed data to take a look. Modify total_files_to_print to determine how many files to print. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "total_files_to_print = 10\n",
    "for folder in respack_folders:\n",
    "    if index == total_files_to_print:\n",
    "        break\n",
    "    path_name = './Respacks/' + folder + '/songs.xml'\n",
    "    print(path_name)\n",
    "    if exists(path_name):\n",
    "        song_xml = xml.dom.minidom.parse(path_name)\n",
    "        songs = song_xml.getElementsByTagName('song')\n",
    "        for song in songs:\n",
    "            index += 1\n",
    "            if index == total_files_to_print:\n",
    "                break\n",
    "            # parsing rhythms\n",
    "            curr_song_name = song.getAttribute('name')\n",
    "            song_path_name = None\n",
    "            is_rhythm = False\n",
    "            is_build_up = False\n",
    "            if len(song.getElementsByTagName('rhythm')) > 0:\n",
    "                is_rhythm = True\n",
    "                song_path_name = path_name = './Respacks/' + folder +'/Songs/' + curr_song_name + '.mp3'\n",
    "            \n",
    "            if len(song.getElementsByTagName('buildup')) > 0:\n",
    "                is_build_up - True\n",
    "                build_up_name = song.getElementsByTagName('buildup')[0].firstChild.nodeValue\n",
    "                song_path_name = path_name = './Respacks/' + folder +'/Songs/' + build_up_name + '.mp3'\n",
    "                    \n",
    "            # load the song\n",
    "            if exists(song_path_name):\n",
    "                print('outputting features for ' + str(song_path_name))\n",
    "                if is_rhythm:\n",
    "                    for key in audio_rhythm_feature_map[curr_song_name].keys():\n",
    "                        print(key)\n",
    "                        print(len(audio_rhythm_feature_map[curr_song_name][key]))\n",
    "                elif is_build_up:\n",
    "                    print(audio_build_up_rhythm_feature_map[build_up_name])\n",
    "            else:\n",
    "                print('file name doesn\\'t exist ' + rhythm_song_path_name)\n",
    "    else:\n",
    "        print('bad path name ' + str(path_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean up. Need to post-process the data for the models ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# features = audio features\n",
    "# labels = rhythm/buildup\n",
    "features = []\n",
    "labels = []\n",
    "for song_name in rhythm_map.keys():\n",
    "    if song_name in audio_rhythm_feature_map:\n",
    "        # if no features were extracted for some reason, then we can't process it.\n",
    "        if len(audio_rhythm_feature_map[song_name]) != 0:\n",
    "            list_to_add = list()\n",
    "            for feature in audio_rhythm_feature_map[song_name]:\n",
    "                audio_features_flattened = np.array(audio_rhythm_feature_map[song_name][feature]).flatten()\n",
    "                for x in audio_features_flattened:\n",
    "                    complex_to_real = x.real + x.imag\n",
    "                    list_to_add.append(complex_to_real)\n",
    "            if len(list_to_add) == 885600:\n",
    "                labels.append(rhythm_map[song_name])\n",
    "                features.append(list_to_add)\n",
    "print(len(labels))\n",
    "print(len(features))\n",
    "# print(total/130)\n",
    "# audio_rhythm_features = audio_rhythm_feature_map.values()\n",
    "# audio_rhythm_labels = rhythm_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "51\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n",
      "885600\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(features))\n",
    "for feature_index in range(len(features)):\n",
    "    print(len(features[feature_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "post_processed_labels = []\n",
    "post_processed_features = []\n",
    "# for index in range(len(labels)):\n",
    "for index in range(10):\n",
    "    for beat_index in range(len(labels[index])):\n",
    "        list_to_add = []\n",
    "        beat_length = len(features[index])//len(labels[index])\n",
    "        for feature_index in range(beat_index*beat_length, (beat_index+1)*beat_length):\n",
    "            value = features[index][feature_index]\n",
    "            list_to_add.append(value)\n",
    "        if len(list_to_add) == 1581:\n",
    "            post_processed_labels.append(labels[index][beat_index])\n",
    "            post_processed_features.append(list_to_add)\n",
    "            \n",
    "    #print(len(post_processed_labels[index]))\n",
    "    #print(len(post_processed_features[index]))\n",
    "print(len(post_processed_labels))\n",
    "print(len(post_processed_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "560\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n",
      "1581\n"
     ]
    }
   ],
   "source": [
    "## Defining a model and attempting to build a model utilizing the cleaned data.\n",
    "print(len(post_processed_labels))\n",
    "print(len(post_processed_features))\n",
    "for feature_index in range(len(post_processed_features)):\n",
    "    print(len(post_processed_features[feature_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(post_processed_features)\n",
    "X_train = scaler.transform(post_processed_features)\n",
    "# print(X_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_splits=2 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-cc30d08d278f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# report performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %.3f (%.3f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     results = parallel(\n\u001b[0;32m--> 268\u001b[0;31m         delayed(_fit_and_score)(\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    671\u001b[0m             raise ValueError(\n\u001b[1;32m    672\u001b[0m                 \u001b[0;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0;34m\" number of members in each class.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             )\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=2 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, features, labels, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frankhu/opt/anaconda3/envs/ai_env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, post_processed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse a single song for output testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocomint.flac\n",
      "parsing chocomint.flac\n"
     ]
    }
   ],
   "source": [
    "# dict(audio_name -> dict(features -> values))\n",
    "path_name = 'chocomint.flac'\n",
    "print(path_name)\n",
    "if exists(path_name):\n",
    "    print('parsing ' + str(path_name))\n",
    "    try:\n",
    "        y, sr = librosa.load(path_name, duration=100, offset=10)\n",
    "        single_song = parseSong(y,sr)\n",
    "    except Exception as e:\n",
    "        print('exception occurred')\n",
    "        print(e)\n",
    "else:\n",
    "    print('bad path name ' + str(path_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::.x.:..:.x:::.::.xx..x:.:::.::.:::.:.:::.:.x.:.x..:::xx.:::.:.:.::::.::...:::..:.::::::::.:..:.::x...:::..xx.:x:....:::...:......x..:.....:.:.x:.x..::.:x::::::.::.::.::..::xx:::x.:....xx.....:.xx.::x...::.x.:.x::::x:.:x..xx::.::..:::x.:::x::::xx..x:.::xx:.:...::x:::::.::..::....:xx.:.:.xx.x..::.::::::.:x.::.x::.::.:::::.:..x....::::.::....x.....:x.::x.::::x:x:.:.:.x::x.x::x.x.::xx..::..x.:::.:.:xx:::..x.:....:x:..:...:x:..::x......:xx:...:.x.....x..x...x..:...::::.::::...::::xxx.....::xxx.::...:..:.:...x..:....x::.x.:x:..::.x:x....:x..:....x..:.x:....x.....x..x.::.xxx.:x..x...::x.:.::x.:::::..:x..x:x..:.xxx..:.:::.x..::.....x.:.:.::x::::::.....:..x...::...::...::x.x..:.x:.x:.:..x........xxx...:....:..x:...:.x::...x.xx::...x:..:....:....:x.x.:xx::....x:..:x...xx:::::x...x:..:....x..:.:...:.:..:.:x.x..:...:........:xx..x.......x::.x..x:.xx:..::..x:xxx:..x.x:.:.x.:.:x:..x:..:..x..xxx......x....x..x.:..:x.x:::..:x..:....:x::x.:.:.:x.:.x....x...x....:.o:xx:.....:.:..x:.....x.....:.x...:.:..x.::..:.....xx.:...x:..:.:x:.x:::.:....x.:.x.:x...x.x....:...:x...:.::x::o:::x..xx::..:.x:..:....:.....:...x..:xx:....x::.:::.x.........xx:x.x...:::.:.:....:....x:.:.x...:x..:::.x:x.:....:....:.::.:....:x...x.xxx.x.xxx..x::x.:.::.......x.......:..:..:.:..x..x:::...x:...::....:.:.....xo.:xx:...:...xx::.::.x:x::....::.:.x:.:...x......x.x.....::..:x...x..:.x:::...x.:......x.xxx.:..x..:...:::.....xx:...:x:...:...:x.:.x...:......x.:.....::.:.::..:.:.....:x:.x..:..x.:xx.....x:..:x.x.....:....x:.::..xx:...x...x...x.:.:.:...x..::.::.....:.......:..:.:x:.:x.:..xx...x.....x.........:xx..:.:...x........x.x.....:x.:...xxx:.xx............:xx:::x...:.x...:.x...:xx:x.:.:.:....:..::.x:xx:........x..:..:.:....x..x.:.x.........x...:.xx:.x:.::...x......x..x...x...:.xxxx......x....x:..x.:..x.:....x.:...::..xx...x..:.....:.::..:::...xx:::..x:xx..::x::..x.xx..x::.....x....:xx....x::x:.::.:....:.x....o...:xx.x.......:..:x.::..:x:...x.....x..:x.:.:..::..x...xxx.:xx......:x..:..:.::.:xx.....x....:..x..:.:..::.x.x..x.x:.:...:.:.:.:...x.x.:.xx...:...:.....x:..:..x:..:...:::..x...:x..xxxxx:.x.:::.....:::x.x.....:..:xx...:...:.....::.:x..x..:::.x:..::......x:.::x.:x.:.:.:x...x.x:::....:..:...:.x..:.x..x:.:x.:..::x:x..xo::......:::::.:x.:.:::..xx..x.x:....xx:...xx:::.:.....:x..:x:x...x.::x..x.:.x::..xx..x..x..:.:.x.::..:x..x.x.....x.:::.....:x:.:x......x.::..::.:xx.x..xxx.x..:..x:xx.x::.xx.:.:..::...:xxxx:.x::..:..::xxx:x:.:..x.:::.........:...x.:::..x::.::...::...:::::....:...xx...xx:x.:.x:.x::xx:.::x..xx.::..:......:.x.:..x.::....x.:.x:..:::.::xxxxx.x..x.x:..x.x.x.xx.x..x:::..x.:..x...o.xx.xxx:..x:..o.x..:.....:..:..:x..x..:x::.:..:...:.o::oxx...:x.x..:x::x..:..::::.:....::.:..::.xx:x::..:x:o:.::x:::::..::..o:...::.::::.:.:....:.::.:::::.....::::::.:::::::.::.:::::::::::::::::::::::::::::::..::..:..::::::..xx::.x:..::..::.:..::x.:.::x.x:::.x.x....x:.:.....xx..:.....::.:.:.x.x.....:.:.::...x:.:..:::::..:.::.....::.:...x.x::..:.::.:x.x.x.:.::.xx:::.:.:...x.:..x..x..x::..xx..::.::...:.:::.x::..::x..::.:.::..x.:.:.xx..:x:.:.:....x.::..:...:......:x:::.:.::..x.x::...x..x.x.x:::::......:::..x::.:x:....:..:.x...x..:..:...:...::.:::...::x.::x.....:.x.:....:.x.x.x..:::.::.xx..x.:.x......:.......:..x..:.::.x..::::.....x...:.:..:..:.x:.x.........x........x.....:..x..:.x..:.:.x.:..:.xx.:xx.::.x...:.:...:::::...x....:::x.....x...:.:....x...:x:.:.x..:.:..:x.:..:.x.x.....x..::.::x..:.:.....::.x:::...x...:.:...x.:.x...........x..:......x.:x:..:....::.....x:.......:.:.x.:....xxx:x.:.....::....x..x.x.xxx.x.x:::......x..x.....:.:.:..x........x:x....:...:::x...:x..:..:.:......xxxxx..::..:..:x..x...x:.xx.:...::.:..:..x:............:...:.x...:....::.:.x...:x........:...::x..::..:x:.xxx.:x.:.....x:x:..:....x..:.....x..x.:.x........::x.....::...:....x.x.:.:x:..x...:......x....x..........:...x:..::....:..:.:..::.:...:...x.x::.:x......:..x:.x.x...x...:..:.....::.......:.....:..:..:....x.x....x::...:.:xx..:..::x...::...x:.x.:..:........::..:.:.:...x:::...:..:........x.x....x:.x..x..:.x....x:xx:x....x.::x..::..:.::.....x:.:.:.....:.::.:.:.xx...:x.:..:.:.:.x.::xx.x:::.:.....::x:.:.x.:......:...::.:.:....:xx:.:.:....:x.x::.:..:x..:.xx.xx.x.:.x..xxx.x.......:.:.x....xx.:.........xx...x........:...:....::.x..x.x....x:..::....::......:.::x:..x:.::..:..:...:...:..:...:xxx.:.........:.x.x..x...xx...xx:.x.::..:..x..:..xx.:.:x.:.....:..::..x....:.........:.x..:..x:..::.x.:..::..x..x....:::.:...:x......xx.......x.::...:.:.x.x:x..x...x..:..::x.x.....:x:x.x.:..x.x:x:..:x.:....xxx.x:.xx.:.x..:..::x.xx:.:..x.::::x.::...:..x..x:.x:..:........:.:.:..x..x...x:........x.:::..::x.::..:..:.x.x.::...:..xx.:xx..xx:....x:.x..:x.....xx.x...:::.:..x..:.....:.::..:..x.x:..:....x.......x::.:.x.:..x....:......x.........:...:.:........::.....:.::.x:.::....:.....:....x.:.:x...::.....:...xxx.:.....x.:.x..:....:..xxx..x.x.:...:.:....:.....x:.:.::x:xx.x....x...x.:...:.....:.....:....:.x.....:x.:.x.:...x....:x..x........x.:::..x...::x.....:x:x.....::x.....x.:.:.xx...:......:x...:.xxx....:x...:..:.::x..x..:......:.:...:....:.::x..:x.x.::....x........:xxxx.:.x:.xx:..::xx.x...x:...::x::.x..xx:....:..x..x...:.:x....:::.x...:x.x:...o:x.....::.:.:...xx:..x...:.....x.:::.x.x..::.....:...x.:::..:.:.x.x..::.xx....:....:x.:..x....:...x........x........xx...:...x..::::::..xx.....x:...::x...x:..x:.:.....x......x...:..x..::.....:xx..:.....:.....:..x...x:..:::.:.x.x:..:.::x.x.xx.:.....:.::...:.x...xx..:.........x..::::.x.:.o.....x::::..:x:...:x.::..x.:.:....:..x:.:::.x...:.x.xx....::..:.x:x:....:x.xx......:x.:xx...:...x:.x:..:x....x.:..::.:.:..:xo:..:....:...::::.:.x:.::::.:::::...:::.:...x::o::.:.::.::.x:.:..x:::x..:.:.:::::.:::.:.x.:x.:..::...x.:x:x.:.x.:.x.:o:.:::...:...x:::::xx...::::.:x::...:.::x..:.xxxx..::.::...x..:..:x:.....:x..::.:..x.::::.:...:...::.x.::..:....:::..::..::.:..:.......::::..:.......:x...:..:x...:xx:....:.:::.:::.:.:...xo.xx.:...xx.x:..:::.x..x:xx:....xxxx:...:::..:.::.:::::...:.....x::::.:x:....:x.:......::.x::xx.:...:x.:.:..::::.....:.:.x..x::.......x..:..:.....:.:..::.::::::x.:.o.x..:x:.:...x..:.:::x:..::x.:.x.....:x....:....x:..:x:.:...:xx:......x..:x.o:..x.x.x:....:x:.:xx::..x..x..:.:::.:x..x....x.:.:...:.x..x..:x:.x..:.x:.:....:..:x......:.xxx.....:::....x...::....x.:.:x..:.:x.:....:.:....x....xx..:.:.:x::::x::x.xx.::.x..x...o..:x:..:..::::....:....xx:...x.:......x..:.:.:..:.::xx::x::x::::.::..:.:..::o..:::x::x.:x::::.:..::x::.::x..:..x:.::..........x.:x...:.::x:.....:::..:..:::.:.::::..xox.:.:.ox.::xx..::xx...:.:.:xx::.:::x.:x.:x.:o:.xxx::.x.x.:.:xxx....:x.:..:.:::.::::.:..:.:::....:.x..:.::xx..:x.x:.xx..x:...x..:.:::.:.x:.:...:.::x.:x...x::.:..xx.x.x..xo:x:.:.:......:.ox::x..:.:::.....xx.:..:x::..x:..x.::...:::x:.:.:.:::...:.::....:...:...:....xxx.:.:..::.:.xxx:x:x::.:.:::x...x:..:..x:...x.::x..:....::.......:.:.:...xx..x..x...:x::.x.x.x:.x:x..:...xx:.x:.....::x:.xxx:.::..x:.:.:..o..x.x.::::.:ox::...:.:x::x.x.xo......::::..:.::xo:.:.xo.x.:.::..:..:......::.:.x.:..:xx:.x.:.x::xx.:.:.x.......x.:....:.x.::...:...::x.x:..:.::::::.:..:..x:.xx::..:..:..::x.:.:xx.oxx::.....:xx.::::..o::x.:.::::..:x.::.:..::::x.x.:..:....:.x:..::x:.......x:.:.xx:.x...:x::.:::::o:.:::..::.....:.:.xx..xo:::.:..x...x:.:...:..:x::..:..::.:.x..:xx:..::::xx:.x.:.:x::x::...::..:.::::...:.:..:...ox::.x:..:..:x.x:::x.:::.:x:::::.:..:x::::.:x:.x:.::..::..:.x:.::::.:..::.:::...::x.:..:..:.:.:.o.x::::.:..::..::::.:::x::...:..x.x.:.::..:xx:.:::.:::::::..:::.:..:x::x:....:.::::.:.:::.x.:..:.::::::....:::::x..:.:::...:.:...:.....:...::.::::.::..:.::..:..::.::..:.:.:x.....:.:.:...:..x.::..:......:..:x:...::.:::.::..:..:::...:.::.:.:.::::::.:::.:::o:.:x...:.x:.x:.:.:.:xx.:.:::::..x:.:..:.::.:.:.::..::xx...x:..::.::::::...:.:::..::..::..:::.:::.o:xx:.:.::x..:.:.:.::::.:::x.:xxx.o::...:.::.....::.:.:.::..:.oxx:..:.:::.....::..::..::...:::...:...:x:::x.::.:.:.:.::.::::..:.:.........:x:..:....:....x:x::.:::::.:..:::.::.::::::.:..::x:..x:::.::.:::..:..:::::::::.::::....::x::::::x::...x..x..:::::.:.::.:.::::.:.x:x:.::.:..::.::::.:::::o.::...:::.:.:::.:::..:.::.:::...:..:...:.x.:::x:x..:..::...:.....:.:.:::.:::..:x.::..:.:.::.:.:....x.::::.::.:o::::::...:::::..::.:.:.::..:::.::..:...:....::::::.:..:::::o.:..:.::::::::.::::::::::.::::::::...:.::.:.:.:.:::..:...:.:.::::....::..:::::...::.::::::::::.::::::::.......:....:....:.:::::.::::::::::.:::::.::.::::::.:::::::::::::::..:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::..:x:......:..x::x..xxx.:x:...x:x.:...::.x..:.x..x...:..x.:..:......x..o.....x::..:.x.....:..:....:.:..:.......:x....::.::x.xx::...:.:::.x..:...x...:x.x.:..x.......x..xx..:x.:x..:.:x:.:::.:x..:..:.x:.::...xx....:..x.:.::..x..x..::..::.:x:.....x:....:.:.......:..:x..:x:...x..:..::....x.x..:::..:...x::x.....x:.x..xx......:..:...:...x....x....o:.:.x.x...:..:::.x.x....x.:.x:.....::.:...::x.:xx.....:..::.......::..x:....xx.:.:..x.....x..:.:x......:xx:::...:..x:.:x:..:x:.x.:.:...x.:x:x....:xx.x.:..:.:xx::.:::.:...:....:.x.x.........:.xx.:..:.::...x.x.x.:..x.:xx....x:.:::..:..:.::x.:...:...x..:....x:.x:....:...x.o.::xx.:.ox:.:..x:x..:x:..x..:.x.:.:...:x...x:x.....:x......xx:.:..xx.:..xx...:.....:.:xxx:.:..:.:.::......:.x:..x...:.:.x..x.::....:xx.xx::..xxx:.:.......x..::......xxxx:.:x.:.xx:.:.:.xx...:x...:xx:..:.:..:..x.:..x:::.:::..x:x.:x.x..:.:.x:..xx...x:.::x:o:...xx:....:::..x.:.xx:o.:.:x:.x::........:....:..:..::.:..x:x....::x..::.::.x....x:..:.x.x...:.:xx.x:.x.x....:x:xx.x..:::....:.:.x....xxx.xxx.::.x.:.:x.xx.x.:.:..:.::..::x::x.:.x:.::.x:.....x.xxx.::xx..::x:..:...:x:x...:.:x:.:....x:..:x:...x:x.x::.:x.x:.::..:..:::.......:x:..x::x..x:xx.:xx.:...:..:......:.:.xx....x.::x:.x.xx...x::.:xx.x::o.....:x....::...x.:x..x.:x.:...x.x.xo.......::..x...:x..:....xx:.:.x.:.x...::.:..x..x..:x:....:::..x..:.::.x.xx.:.:x..:o..::x:x.:..::.:x..x..:x:.oxx:o:..x..o..x..:.o..:x....:.x..xx::x..x...:.:..:x:...x.o.:.:.::::.x:x..:......:.:xx.....:.:x:....x...x...:o.....:.......:xxxx....:.:.:.::x...x:x:xx::..x:x:.....x.:.:.:x:xx.::ox.:::.:x.x::....:xx.....x:.x.xx.....:x..::...x..x......:..xx::..o:...:::x:.:x.x:..:::::.:::..:.:....:.::.:.:..:x......x:.:xx..:.xxx......:..:.x.:.:xx...:.x:....:......:...:.:.::..x:..::x..x:....x..:xxxx.:xx.:.:...o...:.:.x.::...x:x...:..x....:.:xx...x:.::..x:.:::.x.oxxx.xxxx..x..x:.....::....x.::x...x:..x...x..:...x:..:..xx.x.x.:....xxxx..x...x:.:.:::x:o..:x:.:....:..:...:x::::.:.:..x..::.x:.:x::...:..x:::xx:....::..x...x:..x:.:.:::.:....x:.::.x.:...:..:x.:..x..xxx.::x....x.::::x.::.:::.:.xx.x:x:..:..x:.:..::x.xx.:..:x.:...x:.::.:.:.x.:..:.x..x:.o:.x:..x.:.xx.x.x.....:xx.:......x..:....x:...::.:..::...:xxo.:x.xx:.x..:..:xx:...:..x.::.x...xx......:...x.:...::.xxx.:x..x.x...x:..:.:.:...::xx:.o:..:.:x..:.:x..x::.::..:..:..:..:..x:o.x.x.....x..:...x...::........x:..x:::...:...x.:.....x:x:....:...x..::.xx:x:.x...xx..:x.x......::x.:x:...::xx..x.x:.x:..:..x.::..xx:.:.x......::.:::.::...:x.....x::xx.....:ox:::x.::.x..x.:x..:...:...:....x.:..::..::..:.x.::x::x..:::..x..x....:xx.x.::....:.xx.o....x...x.::......:::.x..:..o..x.:...x.::x.:::......:...x.:.::.......:x...:::.:...::.::.x..x:..:...x....:x:.:x:..:.xx.x::.::..x:..:.::.:.xx.:::::..:....x:....:x:::...:.::.::..:::.:..::..:.:....:::.::..:.o.:o.::..::::::..::x:::::::::..::::.::.::x:.::.::x::.:x::.:."
     ]
    }
   ],
   "source": [
    "flattened_feature_input = []\n",
    "for feature in single_song:\n",
    "    flattened_feature_input.extend(single_song[feature])\n",
    "single_feature_input = []\n",
    "flattened_feature_input = np.array(flattened_feature_input).flatten()\n",
    "for index in range(0, len(flattened_feature_input), 1581):\n",
    "    single_feature_input.append([])\n",
    "    for x in flattened_feature_input[index:index+1581]:\n",
    "        # print(x)\n",
    "        complex_to_real = x.real + x.imag\n",
    "        single_feature_input[-1].append(complex_to_real)\n",
    "    # print(len(single_feature_input[-1]))\n",
    "single_feature_input.pop()\n",
    "'''\n",
    "for index in range(len(single_feature_input)):\n",
    "    model.predict(np.array([single_feature_input[index][:2]]))\n",
    "'''\n",
    "single_feature_normalized = scaler.transform(single_feature_input)\n",
    "res = clf.predict(np.array(single_feature_normalized))\n",
    "for index in range(len(res)):\n",
    "    print(res[index],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_feature_input[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
